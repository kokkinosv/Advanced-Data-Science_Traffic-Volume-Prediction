{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Traffic Volume Prediction__\n",
    "<h2 align=\"center\"><b>Advanced Data Science Capstone Poject by</b></h2>\n",
    "<h2 align=\"center\"><b>IBM / Coursera</b></h1>\n",
    "<h2 align=center>Vasilis Kokkinos (September 2019)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Introduction / Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE CASE: Predictive model of traffic volume. It can be used as template for similar situations.\n",
    "\n",
    "DATA SET: Metro Interstate Traffic Volume Data Set\n",
    "Hourly Interstate 94 Westbound traffic volume for MN DoT ATR station 301, roughly midway between Minneapolis and St Paul, MN. Hourly weather features and holidays included for impacts on traffic volume.\n",
    "\n",
    "Source: https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Attribute Information:__\n",
    "\n",
    "__holiday:__ Categorical US National holidays plus regional holiday, Minnesota State Fair\n",
    "\n",
    "__temp:__ Numeric Average temp in kelvin\n",
    "\n",
    "__rain_1h:__ Numeric Amount in mm of rain that occurred in the hour\n",
    "\n",
    "__snow_1h:__ Numeric Amount in mm of snow that occurred in the hour\n",
    "\n",
    "__clouds_all:__ Numeric Percentage of cloud cover\n",
    "\n",
    "__weather_main:__ Categorical Short textual description of the current weather\n",
    "\n",
    "__weather_description:__ Categorical Longer textual description of the current weather\n",
    "\n",
    "__date_time:__ DateTime Hour of the data collected in local CST time\n",
    "\n",
    "__traffic_volume:__ Numeric Hourly I-94 ATR 301 reported westbound traffic volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Data Cleansing__ was performed in a previous step in the notebook __traffic_volume.etl.py.v01.ipynb__\n",
    "\n",
    "In that step:\n",
    "* duplicate rows (based on the _'date_time'_ column) were removed from the data set\n",
    "* the values for the _'temp'_ outliers were appropriately changed\n",
    "* the row with the outlier for column _'rain_1h' was removed from the data set\n",
    "\n",
    "The resulting data set was saved in _parquet_ format in __traffic_volume_etl_df.parquet__\n",
    "    \n",
    "In the current notebook, I will perform all the __Feature Creation / Transformation__ steps needed for the model definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages, initialize Apache Spark session and add supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.44.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Traffic Volume Prediction</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x225a55a5308>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Traffic Volume Prediction').getOrCreate()\n",
    "sqlContext = SQLContext(spark)\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an sql context so that we can query data files in sql like syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Read in the data set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- holiday: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- rain_1h: double (nullable = true)\n",
      " |-- snow_1h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- date_time: timestamp (nullable = true)\n",
      " |-- traffic_volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('traffic_volume_etl_df.parquet')\n",
    "\n",
    "df.createOrReplaceTempView('df')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data set checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+-------+----------+------------+-----------------------+-------------------+--------------+\n",
      "|holiday|temp  |rain_1h|snow_1h|clouds_all|weather_main|weather_description    |date_time          |traffic_volume|\n",
      "+-------+------+-------+-------+----------+------------+-----------------------+-------------------+--------------+\n",
      "|None   |280.62|0.0    |0.0    |96        |Drizzle     |light intensity drizzle|2012-10-20 03:00:00|432           |\n",
      "|None   |279.24|0.0    |0.0    |1         |Clear       |sky is clear           |2012-11-16 18:00:00|5074          |\n",
      "|None   |284.82|0.0    |0.0    |75        |Clouds      |broken clouds          |2012-11-22 18:00:00|3083          |\n",
      "|None   |270.81|0.0    |0.0    |90        |Snow        |snow                   |2012-12-10 20:00:00|2131          |\n",
      "|None   |269.47|0.0    |0.0    |20        |Clouds      |few clouds             |2012-12-14 09:00:00|5113          |\n",
      "|None   |260.19|0.0    |0.0    |1         |Clear       |sky is clear           |2012-12-22 04:00:00|394           |\n",
      "|None   |260.5 |0.0    |0.0    |75        |Clouds      |broken clouds          |2012-12-24 07:00:00|2440          |\n",
      "|None   |256.78|0.0    |0.0    |75        |Clouds      |broken clouds          |2012-12-26 23:00:00|1139          |\n",
      "|None   |252.84|0.0    |0.0    |40        |Haze        |haze                   |2013-01-02 09:00:00|4417          |\n",
      "|None   |268.44|0.0    |0.0    |90        |Snow        |heavy snow             |2013-01-13 03:00:00|306           |\n",
      "|None   |257.97|0.0    |0.0    |1         |Clear       |sky is clear           |2013-01-14 22:00:00|1347          |\n",
      "|None   |250.33|0.0    |0.0    |67        |Clouds      |broken clouds          |2013-02-03 08:00:00|1630          |\n",
      "|None   |253.88|0.0    |0.0    |32        |Clouds      |scattered clouds       |2013-02-04 04:00:00|742           |\n",
      "|None   |269.82|0.0    |0.0    |40        |Clouds      |scattered clouds       |2013-02-06 15:00:00|5597          |\n",
      "|None   |268.96|0.0    |0.0    |90        |Haze        |haze                   |2013-02-08 03:00:00|339           |\n",
      "|None   |274.06|0.0    |0.0    |75        |Clouds      |broken clouds          |2013-02-14 12:00:00|5026          |\n",
      "|None   |271.84|0.0    |0.0    |90        |Clouds      |overcast clouds        |2013-02-18 18:00:00|3825          |\n",
      "|None   |270.79|0.0    |0.0    |90        |Clouds      |overcast clouds        |2013-02-28 23:00:00|1336          |\n",
      "|None   |273.11|0.0    |0.0    |90        |Mist        |mist                   |2013-03-16 10:00:00|4108          |\n",
      "|None   |271.54|0.0    |0.0    |1         |Clear       |sky is clear           |2013-03-26 11:00:00|4545          |\n",
      "+-------+------+-------+-------+----------+------------+-----------------------+-------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in the dataframe: 40569\n"
     ]
    }
   ],
   "source": [
    "print('Number of entries in the dataframe: {}'.format(df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Feature Engineering__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add month, day_of_week and hour_of_day columns\n",
    "I will add columns with values of month, day and time excluding the year, because the year column should not normally have an impact on the traffic volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+-------+----------+------------+-----------------------+-------------------+--------------+-----+-----------+-----------+\n",
      "|holiday|temp  |rain_1h|snow_1h|clouds_all|weather_main|weather_description    |date_time          |traffic_volume|month|day_of_week|hour_of_day|\n",
      "+-------+------+-------+-------+----------+------------+-----------------------+-------------------+--------------+-----+-----------+-----------+\n",
      "|None   |280.62|0.0    |0.0    |96        |Drizzle     |light intensity drizzle|2012-10-20 03:00:00|432           |10   |6          |3          |\n",
      "|None   |279.24|0.0    |0.0    |1         |Clear       |sky is clear           |2012-11-16 18:00:00|5074          |11   |5          |18         |\n",
      "|None   |284.82|0.0    |0.0    |75        |Clouds      |broken clouds          |2012-11-22 18:00:00|3083          |11   |4          |18         |\n",
      "|None   |270.81|0.0    |0.0    |90        |Snow        |snow                   |2012-12-10 20:00:00|2131          |12   |1          |20         |\n",
      "|None   |269.47|0.0    |0.0    |20        |Clouds      |few clouds             |2012-12-14 09:00:00|5113          |12   |5          |9          |\n",
      "|None   |260.19|0.0    |0.0    |1         |Clear       |sky is clear           |2012-12-22 04:00:00|394           |12   |6          |4          |\n",
      "|None   |260.5 |0.0    |0.0    |75        |Clouds      |broken clouds          |2012-12-24 07:00:00|2440          |12   |1          |7          |\n",
      "|None   |256.78|0.0    |0.0    |75        |Clouds      |broken clouds          |2012-12-26 23:00:00|1139          |12   |3          |23         |\n",
      "|None   |252.84|0.0    |0.0    |40        |Haze        |haze                   |2013-01-02 09:00:00|4417          |1    |3          |9          |\n",
      "|None   |268.44|0.0    |0.0    |90        |Snow        |heavy snow             |2013-01-13 03:00:00|306           |1    |7          |3          |\n",
      "+-------+------+-------+-------+----------+------------+-----------------------+-------------------+--------------+-----+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "df = df.withColumn('month', date_format(df['date_time'], 'M').cast(IntegerType()))\n",
    "df = df.withColumn('day_of_week', date_format('date_time', 'u').cast(IntegerType()))\n",
    "df = df.withColumn('hour_of_day', date_format('date_time', 'H').cast(IntegerType()))\n",
    "\n",
    "# Refresh the temporary view of the data frame\n",
    "df.createOrReplaceTempView('df')\n",
    "df.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The date_time column can now be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+-------+----------+------------+-----------------------+--------------+-----+-----------+-----------+\n",
      "|holiday|temp  |rain_1h|snow_1h|clouds_all|weather_main|weather_description    |traffic_volume|month|day_of_week|hour_of_day|\n",
      "+-------+------+-------+-------+----------+------------+-----------------------+--------------+-----+-----------+-----------+\n",
      "|None   |280.62|0.0    |0.0    |96        |Drizzle     |light intensity drizzle|432           |10   |6          |3          |\n",
      "|None   |279.24|0.0    |0.0    |1         |Clear       |sky is clear           |5074          |11   |5          |18         |\n",
      "|None   |284.82|0.0    |0.0    |75        |Clouds      |broken clouds          |3083          |11   |4          |18         |\n",
      "|None   |270.81|0.0    |0.0    |90        |Snow        |snow                   |2131          |12   |1          |20         |\n",
      "|None   |269.47|0.0    |0.0    |20        |Clouds      |few clouds             |5113          |12   |5          |9          |\n",
      "|None   |260.19|0.0    |0.0    |1         |Clear       |sky is clear           |394           |12   |6          |4          |\n",
      "|None   |260.5 |0.0    |0.0    |75        |Clouds      |broken clouds          |2440          |12   |1          |7          |\n",
      "|None   |256.78|0.0    |0.0    |75        |Clouds      |broken clouds          |1139          |12   |3          |23         |\n",
      "|None   |252.84|0.0    |0.0    |40        |Haze        |haze                   |4417          |1    |3          |9          |\n",
      "|None   |268.44|0.0    |0.0    |90        |Snow        |heavy snow             |306           |1    |7          |3          |\n",
      "|None   |257.97|0.0    |0.0    |1         |Clear       |sky is clear           |1347          |1    |1          |22         |\n",
      "|None   |250.33|0.0    |0.0    |67        |Clouds      |broken clouds          |1630          |2    |7          |8          |\n",
      "|None   |253.88|0.0    |0.0    |32        |Clouds      |scattered clouds       |742           |2    |1          |4          |\n",
      "|None   |269.82|0.0    |0.0    |40        |Clouds      |scattered clouds       |5597          |2    |3          |15         |\n",
      "|None   |268.96|0.0    |0.0    |90        |Haze        |haze                   |339           |2    |5          |3          |\n",
      "|None   |274.06|0.0    |0.0    |75        |Clouds      |broken clouds          |5026          |2    |4          |12         |\n",
      "|None   |271.84|0.0    |0.0    |90        |Clouds      |overcast clouds        |3825          |2    |1          |18         |\n",
      "|None   |270.79|0.0    |0.0    |90        |Clouds      |overcast clouds        |1336          |2    |4          |23         |\n",
      "|None   |273.11|0.0    |0.0    |90        |Mist        |mist                   |4108          |3    |6          |10         |\n",
      "|None   |271.54|0.0    |0.0    |1         |Clear       |sky is clear           |4545          |3    |2          |11         |\n",
      "+-------+------+-------+-------+----------+------------+-----------------------+--------------+-----+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('date_time')\n",
    "\n",
    "# Refresh the temporary view of the data frame\n",
    "df.createOrReplaceTempView('df')\n",
    "df.show(20, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the newly created columns month, day_of_week and hour_of_day to check for any irrational values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create visually appealing boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boxplot(data, columns, size=(5, 3), title=''):\n",
    "    fig = plt.figure(1, figsize=size)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    bp = ax.boxplot(data)\n",
    "    bp = ax.boxplot(data, patch_artist=True)\n",
    "\n",
    "    for box in bp['boxes']:\n",
    "        # change outline color\n",
    "        box.set(color='#7570b3', linewidth=2)\n",
    "        # change fill color\n",
    "        box.set(facecolor = '#1e3aab')\n",
    "\n",
    "    for whisker in bp['whiskers']:\n",
    "        whisker.set(color='#7570b3', linewidth=2)\n",
    "\n",
    "    for cap in bp['caps']:\n",
    "        cap.set(color='#7570b3', linewidth=2)\n",
    "\n",
    "    ## change color and linewidth of the medians\n",
    "    for median in bp['medians']:\n",
    "        median.set(color='#b2df8a', linewidth=2)\n",
    "\n",
    "    ## change the style of fliers and their fill\n",
    "    for flier in bp['fliers']:\n",
    "        flier.set(marker='o', color='#e7298a', alpha=0.5)\n",
    "\n",
    "    # Change x-axis labels and remove tick marks from the top and right axes.\n",
    "    ## Custom x-axis labels\n",
    "    ax.set_xticklabels(columns)\n",
    "\n",
    "    ## Remove top axes and right axes ticks\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    \n",
    "    ax.set_title(title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Since the number of rows in the dataframe is not too high, we can afford to use ALL the data points\n",
    "result1 = spark.sql('select month from df').rdd.map(lambda row: row.month).sample(False, 0.99).collect()\n",
    "result2 = spark.sql('select day_of_week from df').rdd.map(lambda row: row.day_of_week).sample(False, 0.99).collect()\n",
    "result3 = spark.sql('select hour_of_day from df').rdd.map(lambda row: row.hour_of_day).sample(False, 0.99).collect()\n",
    "data = np.array([result1, result2, result3])\n",
    "\n",
    "create_boxplot(data, ['month', 'day_of_week', 'hour_of_day'], size=(8, 6), title='Month, Day, Hour Box Plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the three columns all make sense and there are no outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the values of the columns 'holiday', 'weather_main', 'weather_description' to indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- holiday: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- rain_1h: double (nullable = true)\n",
      " |-- snow_1h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- traffic_volume: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- hour_of_day: integer (nullable = true)\n",
      " |-- holidayIndex: double (nullable = false)\n",
      " |-- weatherMainIndex: double (nullable = false)\n",
      " |-- weatherDescIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"holiday\", outputCol=\"holidayIndex\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "indexer = StringIndexer(inputCol=\"weather_main\", outputCol=\"weatherMainIndex\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "indexer = StringIndexer(inputCol=\"weather_description\", outputCol=\"weatherDescIndex\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "# Refresh the temporary view of the data frame\n",
    "df.createOrReplaceTempView('df')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cast the three new colums to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- holiday: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- rain_1h: double (nullable = true)\n",
      " |-- snow_1h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- traffic_volume: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- hour_of_day: integer (nullable = true)\n",
      " |-- holidayIndex: integer (nullable = true)\n",
      " |-- weatherMainIndex: integer (nullable = true)\n",
      " |-- weatherDescIndex: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('holidayIndex', df['holidayIndex'].cast(IntegerType()))\n",
    "df = df.withColumn('weatherMainIndex', df['weatherMainIndex'].cast(IntegerType()))\n",
    "df = df.withColumn('weatherDescIndex', df['weatherDescIndex'].cast(IntegerType()))\n",
    "\n",
    "# Refresh the temporary view of the data frame\n",
    "df.createOrReplaceTempView('df')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+-------+----------+------------+-----------------------+--------------+-----+-----------+-----------+------------+----------------+----------------+\n",
      "|holiday|temp  |rain_1h|snow_1h|clouds_all|weather_main|weather_description    |traffic_volume|month|day_of_week|hour_of_day|holidayIndex|weatherMainIndex|weatherDescIndex|\n",
      "+-------+------+-------+-------+----------+------------+-----------------------+--------------+-----+-----------+-----------+------------+----------------+----------------+\n",
      "|None   |280.62|0.0    |0.0    |96        |Drizzle     |light intensity drizzle|432           |10   |6          |3          |0           |6               |10              |\n",
      "|None   |279.24|0.0    |0.0    |1         |Clear       |sky is clear           |5074          |11   |5          |18         |0           |1               |0               |\n",
      "|None   |284.82|0.0    |0.0    |75        |Clouds      |broken clouds          |3083          |11   |4          |18         |0           |0               |2               |\n",
      "|None   |270.81|0.0    |0.0    |90        |Snow        |snow                   |2131          |12   |1          |20         |0           |4               |16              |\n",
      "|None   |269.47|0.0    |0.0    |20        |Clouds      |few clouds             |5113          |12   |5          |9          |0           |0               |6               |\n",
      "|None   |260.19|0.0    |0.0    |1         |Clear       |sky is clear           |394           |12   |6          |4          |0           |1               |0               |\n",
      "|None   |260.5 |0.0    |0.0    |75        |Clouds      |broken clouds          |2440          |12   |1          |7          |0           |0               |2               |\n",
      "|None   |256.78|0.0    |0.0    |75        |Clouds      |broken clouds          |1139          |12   |3          |23         |0           |0               |2               |\n",
      "|None   |252.84|0.0    |0.0    |40        |Haze        |haze                   |4417          |1    |3          |9          |0           |5               |9               |\n",
      "|None   |268.44|0.0    |0.0    |90        |Snow        |heavy snow             |306           |1    |7          |3          |0           |4               |12              |\n",
      "|None   |257.97|0.0    |0.0    |1         |Clear       |sky is clear           |1347          |1    |1          |22         |0           |1               |0               |\n",
      "|None   |250.33|0.0    |0.0    |67        |Clouds      |broken clouds          |1630          |2    |7          |8          |0           |0               |2               |\n",
      "|None   |253.88|0.0    |0.0    |32        |Clouds      |scattered clouds       |742           |2    |1          |4          |0           |0               |4               |\n",
      "|None   |269.82|0.0    |0.0    |40        |Clouds      |scattered clouds       |5597          |2    |3          |15         |0           |0               |4               |\n",
      "|None   |268.96|0.0    |0.0    |90        |Haze        |haze                   |339           |2    |5          |3          |0           |5               |9               |\n",
      "|None   |274.06|0.0    |0.0    |75        |Clouds      |broken clouds          |5026          |2    |4          |12         |0           |0               |2               |\n",
      "|None   |271.84|0.0    |0.0    |90        |Clouds      |overcast clouds        |3825          |2    |1          |18         |0           |0               |1               |\n",
      "|None   |270.79|0.0    |0.0    |90        |Clouds      |overcast clouds        |1336          |2    |4          |23         |0           |0               |1               |\n",
      "|None   |273.11|0.0    |0.0    |90        |Mist        |mist                   |4108          |3    |6          |10         |0           |3               |3               |\n",
      "|None   |271.54|0.0    |0.0    |1         |Clear       |sky is clear           |4545          |3    |2          |11         |0           |1               |0               |\n",
      "+-------+------+-------+-------+----------+------------+-----------------------+--------------+-----+-----------+-----------+------------+----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Before we drop the 'String' columns 'holiday', 'weather_main' and 'weather_description' let's see how their values were mapped by the StringIndexer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the __'holiday'__ column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------------+-----+\n",
      "|holiday                  |holidayIndex|count|\n",
      "+-------------------------+------------+-----+\n",
      "|None                     |0           |40516|\n",
      "|Labor Day                |1           |5    |\n",
      "|Thanksgiving Day         |2           |5    |\n",
      "|Independence Day         |3           |5    |\n",
      "|State Fair               |4           |5    |\n",
      "|Veterans Day             |5           |5    |\n",
      "|Columbus Day             |6           |5    |\n",
      "|New Years Day            |7           |5    |\n",
      "|Christmas Day            |8           |5    |\n",
      "|Washingtons Birthday     |9           |5    |\n",
      "|Memorial Day             |10          |5    |\n",
      "|Martin Luther King Jr Day|11          |3    |\n",
      "+-------------------------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select holiday, holidayIndex, count(*) as count from df group by holiday, holidayIndex order by holidayIndex').show(50, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the __'weather_main'__ column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+-----+\n",
      "|weather_main|weatherMainIndex|count|\n",
      "+------------+----------------+-----+\n",
      "|Clouds      |0               |15121|\n",
      "|Clear       |1               |13366|\n",
      "|Rain        |2               |3857 |\n",
      "|Mist        |3               |3648 |\n",
      "|Snow        |4               |1924 |\n",
      "|Haze        |5               |852  |\n",
      "|Drizzle     |6               |844  |\n",
      "|Thunderstorm|7               |537  |\n",
      "|Fog         |8               |411  |\n",
      "|Smoke       |9               |8    |\n",
      "|Squall      |10              |1    |\n",
      "+------------+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select weather_main, weatherMainIndex, count(*) as count from df group by weather_main, weatherMainIndex order by weatherMainIndex').show(50, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally for the __'weather_description'__ column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+----------------+-----+\n",
      "|weather_description                |weatherDescIndex|count|\n",
      "+-----------------------------------+----------------+-----+\n",
      "|sky is clear                       |0               |13366|\n",
      "|overcast clouds                    |1               |5072 |\n",
      "|broken clouds                      |2               |4649 |\n",
      "|mist                               |3               |3648 |\n",
      "|scattered clouds                   |4               |3455 |\n",
      "|light rain                         |5               |2480 |\n",
      "|few clouds                         |6               |1945 |\n",
      "|light snow                         |7               |1406 |\n",
      "|moderate rain                      |8               |1031 |\n",
      "|haze                               |9               |852  |\n",
      "|light intensity drizzle            |10              |537  |\n",
      "|fog                                |11              |411  |\n",
      "|heavy snow                         |12              |378  |\n",
      "|proximity thunderstorm             |13              |373  |\n",
      "|drizzle                            |14              |286  |\n",
      "|heavy intensity rain               |15              |234  |\n",
      "|snow                               |16              |128  |\n",
      "|proximity shower rain              |17              |92   |\n",
      "|thunderstorm                       |18              |72   |\n",
      "|thunderstorm with heavy rain       |19              |26   |\n",
      "|proximity thunderstorm with rain   |20              |25   |\n",
      "|heavy intensity drizzle            |21              |21   |\n",
      "|thunderstorm with light rain       |22              |21   |\n",
      "|thunderstorm with rain             |23              |13   |\n",
      "|very heavy rain                    |24              |11   |\n",
      "|light shower snow                  |25              |9    |\n",
      "|light intensity shower rain        |26              |9    |\n",
      "|smoke                              |27              |8    |\n",
      "|thunderstorm with light drizzle    |28              |4    |\n",
      "|proximity thunderstorm with drizzle|29              |3    |\n",
      "|shower snow                        |30              |1    |\n",
      "|sleet                              |31              |1    |\n",
      "|light rain and snow                |32              |1    |\n",
      "|SQUALLS                            |33              |1    |\n",
      "+-----------------------------------+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select weather_description, weatherDescIndex, count(*) as count from df group by weather_description, weatherDescIndex order by weatherDescIndex').show(50, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now, let's drop the three columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+----------+--------------+-----+-----------+-----------+------------+----------------+----------------+\n",
      "|temp  |rain_1h|snow_1h|clouds_all|traffic_volume|month|day_of_week|hour_of_day|holidayIndex|weatherMainIndex|weatherDescIndex|\n",
      "+------+-------+-------+----------+--------------+-----+-----------+-----------+------------+----------------+----------------+\n",
      "|280.62|0.0    |0.0    |96        |432           |10   |6          |3          |0           |6               |10              |\n",
      "|279.24|0.0    |0.0    |1         |5074          |11   |5          |18         |0           |1               |0               |\n",
      "|284.82|0.0    |0.0    |75        |3083          |11   |4          |18         |0           |0               |2               |\n",
      "|270.81|0.0    |0.0    |90        |2131          |12   |1          |20         |0           |4               |16              |\n",
      "|269.47|0.0    |0.0    |20        |5113          |12   |5          |9          |0           |0               |6               |\n",
      "|260.19|0.0    |0.0    |1         |394           |12   |6          |4          |0           |1               |0               |\n",
      "|260.5 |0.0    |0.0    |75        |2440          |12   |1          |7          |0           |0               |2               |\n",
      "|256.78|0.0    |0.0    |75        |1139          |12   |3          |23         |0           |0               |2               |\n",
      "|252.84|0.0    |0.0    |40        |4417          |1    |3          |9          |0           |5               |9               |\n",
      "|268.44|0.0    |0.0    |90        |306           |1    |7          |3          |0           |4               |12              |\n",
      "|257.97|0.0    |0.0    |1         |1347          |1    |1          |22         |0           |1               |0               |\n",
      "|250.33|0.0    |0.0    |67        |1630          |2    |7          |8          |0           |0               |2               |\n",
      "|253.88|0.0    |0.0    |32        |742           |2    |1          |4          |0           |0               |4               |\n",
      "|269.82|0.0    |0.0    |40        |5597          |2    |3          |15         |0           |0               |4               |\n",
      "|268.96|0.0    |0.0    |90        |339           |2    |5          |3          |0           |5               |9               |\n",
      "|274.06|0.0    |0.0    |75        |5026          |2    |4          |12         |0           |0               |2               |\n",
      "|271.84|0.0    |0.0    |90        |3825          |2    |1          |18         |0           |0               |1               |\n",
      "|270.79|0.0    |0.0    |90        |1336          |2    |4          |23         |0           |0               |1               |\n",
      "|273.11|0.0    |0.0    |90        |4108          |3    |6          |10         |0           |3               |3               |\n",
      "|271.54|0.0    |0.0    |1         |4545          |3    |2          |11         |0           |1               |0               |\n",
      "+------+-------+-------+----------+--------------+-----+-----------+-----------+------------+----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('holiday').drop('weather_main').drop('weather_description')\n",
    "\n",
    "# Refresh the temporary view of the data frame\n",
    "df.createOrReplaceTempView('df_temp')\n",
    "df.show(20, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data frame in __parquet__ format for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(1)\n",
    "df.write.parquet('traffic_volume_feature_eng_df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Summary__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a final transformed data frame that we can use to create the prediction model for the traffic volume.\n",
    "\n",
    "The data frame is saved in __parquet__ format and is ready to be consumed for the model definition, traininng and testing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
